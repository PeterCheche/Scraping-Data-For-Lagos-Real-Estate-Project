{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import The Neccessary Library\n",
        "\n",
        "#### **What I want to d**o:\n",
        "I want to import the necessary libraries for web scraping, data manipulation, and data visualization, as well as for building and evaluating machine learning models.\n",
        "\n",
        "#### **Why I want to do it:**\n",
        "I need these libraries to collect data from websites, process and analyze the data, and visualize the findings using PowerBI\n",
        "\n",
        "#### **How I want to do it:**\n",
        "- `import requests`: This library will allow me to send HTTP requests to retrieve data from web pages.\n",
        "- `from bs4 import BeautifulSoup`: BeautifulSoup is used for parsing HTML and XML documents, making it easier to extract data from web pages.\n",
        "- `import pandas as pd`: Pandas is a powerful data manipulation library that helps in handling structured data effectively.\n",
        "- `import numpy as np`: NumPy is used for numerical operations and handling arrays.\n",
        "- `import seaborn as sns`: Seaborn is a visualization library based on Matplotlib that provides a high-level interface for drawing attractive statistical graphics.\n",
        "- `import matplotlib.pyplot as plt`: Matplotlib is a plotting library used to create static, interactive, and animated visualizations in Python.\n",
        "- `from sklearn.model_selection import train_test_split`: This function is used to split datasets into training and testing sets, which is essential for evaluating machine learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "hPDgSOba4vMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the needed libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "S493r4Ny8EeM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Result**:\n",
        "I successfully imported the libraries needed for the data"
      ],
      "metadata": {
        "id": "UfDIijxU0Yg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "W0CCxJpl0QTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape The Data From Nigerian Properties Website\n",
        "\n",
        "#### **What I want to do:**\n",
        "I want to scrape property listings from a website that features flats and apartments for rent in Lagos, Nigeria. The goal is to collect data such as property names, prices, addresses, and additional information.\n",
        "\n",
        "#### **Why I want to do it:**\n",
        "I want to gather this data to analyze the rental market in Lagos, understand pricing trends, and identify available properties. This information can be useful for potential renters or investors looking to make informed decisions.\n",
        "\n",
        "#### **How I want to do it:**\n",
        "- Initialize empty lists: `names`, `prices`, `addresses`, and `info` to store the scraped data.\n",
        "- Use a `for` loop to iterate over a specified range (in this case, just one page) to construct the URL for the property listings.\n",
        "- Send a GET request to the constructed URL using `requests.get(url)` and parse the response content with BeautifulSoup.\n",
        "- Use `soup.find_all()` to extract property names, prices, addresses, and additional information from the HTML structure of the page:\n",
        "  - `names_raw`: Extracts property names from the specified HTML tags and classes.\n",
        "  - `prices_raw`: Extracts property prices, which may include currency symbols.\n",
        "  - `address_raw`: Extracts the addresses of the properties.\n",
        "  - `info_raw`: Extracts additional information about the properties.\n",
        "- Clean the `prices` list by removing currency symbols (₦ and $).\n",
        "- Print the lengths of the lists to ensure the data has been collected correctly.\n",
        "- Create a DataFrame using Pandas to organize the collected data into a structured format.\n",
        "- Save the DataFrame to a CSV file named 'Lagos_properties.csv' for further analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "yAsxU2cQ5m2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myhaESz87lSm"
      },
      "outputs": [],
      "source": [
        "names = []\n",
        "prices = []\n",
        "addresses = []\n",
        "info = []\n",
        "\n",
        "for i in range(1,2):\n",
        "  url = 'https://nigeriapropertycentre.com/for-rent/flats-apartments/lagos/showtype?page='+str(i)\n",
        "  response =requests.get(url)\n",
        "  soup = BeautifulSoup(response.content,'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "  names_raw = soup.find_all('h4', class_='content-title')\n",
        "  for i in names_raw:\n",
        "    n = i.text\n",
        "    names.append(n)\n",
        "\n",
        "\n",
        "\n",
        "  prices_raw = soup.find_all('span', class_='price')\n",
        "  for i in prices_raw:\n",
        "    p = i.text\n",
        "    prices.append(p)\n",
        "\n",
        "\n",
        "  address_raw = soup.find_all('address', class_='voffset-bottom-10')\n",
        "  for i in address_raw:\n",
        "    a = i.text\n",
        "    addresses.append(a)\n",
        "\n",
        "\n",
        "\n",
        "  info_raw = soup.find_all('ul', class_='aux-info')\n",
        "  for i in info_raw:\n",
        "    a = i.text\n",
        "    info.append(a)\n",
        "\n",
        "\n",
        "\n",
        "# Remove both Naira and Dollar signs\n",
        "prices = [item for item in prices if item not in ['₦', '$']]\n",
        "\n",
        "\n",
        "print(len(names))\n",
        "print(len(prices))\n",
        "\n",
        "print(len(addresses))\n",
        "print(len(info))\n",
        "\n",
        "df = pd.DataFrame({'Name':names,'Price':prices,'Address':addresses,'Info':info})\n",
        "\n",
        "\n",
        "df.to_csv('Lagos_properties.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Result:**\n",
        "The data was scraped successfully but I only did 2 pages, this can be increased based on the number of pages available. The 2 pages I did here was for test only."
      ],
      "metadata": {
        "id": "0BHnn-bm1Sa1"
      }
    }
  ]
}