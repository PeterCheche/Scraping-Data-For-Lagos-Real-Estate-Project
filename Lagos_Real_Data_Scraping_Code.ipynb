{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I scraped data using beautiful soup.\n",
        "\n",
        "This code block imports libraries required for web scraping, data analysis, visualization, and machine learning tasks:\n",
        "\n",
        "- **requests**: Sends HTTP requests to fetch web content, such as HTML pages, from websites.\n",
        "- **BeautifulSoup**: Parses and navigates HTML content, enabling extraction of specific data elements from web pages.\n",
        "- **pandas**: Provides tools for data manipulation and analysis, allowing structured representation of data in tabular formats like DataFrames.\n",
        "- **numpy**: Adds support for numerical computing, including arrays and mathematical operations.\n",
        "- **seaborn**: A statistical data visualization library based on Matplotlib, used for creating visually appealing and informative plots.\n",
        "- **matplotlib.pyplot**: The plotting interface for Matplotlib, used to create static, interactive, and animated visualizations.\n",
        "- **sklearn.model_selection.train_test_split**: A method from Scikit-learn for splitting datasets into training and testing subsets, crucial for building and evaluating machine learning models.\n"
      ],
      "metadata": {
        "id": "hPDgSOba4vMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the needed libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "S493r4Ny8EeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block belows scrapes property data from the Nigeria Property Centre website and saves it as a CSV file:\n",
        "\n",
        "- **Initialize empty lists**:  \n",
        "  `names`, `prices`, `addresses`, and `info` are created to store the scraped property names, prices, addresses, and additional information.\n",
        "\n",
        "- **Iterate through pages**:  \n",
        "  The code loops through a single page of the property listing site (`page=1`) using a `for` loop. For larger datasets, increase the range to include more pages.\n",
        "\n",
        "- **Send HTTP request**:  \n",
        "  `requests.get` fetches the HTML content of the specified page URL, and BeautifulSoup parses it for data extraction.\n",
        "\n",
        "1. **Scrape property names**:  \n",
        "   - The `find_all` method locates HTML elements with the class `content-title`, which contain property names.  \n",
        "   - The text of each element is appended to the `names` list.\n",
        "\n",
        "2. **Scrape property prices**:  \n",
        "   - Prices are located using the `price` class.  \n",
        "   - Extracted prices are added to the `prices` list.\n",
        "\n",
        "3. **Scrape property addresses**:  \n",
        "   - Addresses are extracted from `<address>` tags with the `voffset-bottom-10` class.  \n",
        "   - These are appended to the `addresses` list.\n",
        "\n",
        "4. **Scrape additional information**:  \n",
        "   - Details like bedrooms, bathrooms, and other auxiliary information are found using the `aux-info` class.  \n",
        "   - These are stored in the `info` list.\n",
        "\n",
        "- **Clean scraped prices**:  \n",
        "  The code removes any entries in the `prices` list that contain symbols like `₦` or `$`.\n",
        "\n",
        "- **Validate scraped data**:  \n",
        "  The `len` function prints the lengths of the `names`, `prices`, `addresses`, and `info` lists to ensure data integrity.\n",
        "\n",
        "- **Create a DataFrame**:  \n",
        "  A pandas DataFrame, `df`, is constructed using the scraped data, with columns `Name`, `Price`, `Address`, and `Info`.\n",
        "\n",
        "- **Save data to CSV**:  \n",
        "  The DataFrame is exported to a CSV file named `Lagos_properties.csv` for further analysis or sharing.\n"
      ],
      "metadata": {
        "id": "yAsxU2cQ5m2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myhaESz87lSm",
        "outputId": "e09415e8-4223-43c5-82da-6397972e198d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "21\n",
            "21\n",
            "21\n"
          ]
        }
      ],
      "source": [
        "names = []\n",
        "prices = []\n",
        "addresses = []\n",
        "info = []\n",
        "\n",
        "for i in range(1,2):\n",
        "  url = 'https://nigeriapropertycentre.com/for-rent/flats-apartments/lagos/showtype?page='+str(i)\n",
        "  response =requests.get(url)\n",
        "  soup = BeautifulSoup(response.content,'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "  names_raw = soup.find_all('h4', class_='content-title')\n",
        "  for i in names_raw:\n",
        "    n = i.text\n",
        "    names.append(n)\n",
        "\n",
        "\n",
        "\n",
        "  prices_raw = soup.find_all('span', class_='price')\n",
        "  for i in prices_raw:\n",
        "    p = i.text\n",
        "    prices.append(p)\n",
        "\n",
        "\n",
        "  address_raw = soup.find_all('address', class_='voffset-bottom-10')\n",
        "  for i in address_raw:\n",
        "    a = i.text\n",
        "    addresses.append(a)\n",
        "\n",
        "\n",
        "\n",
        "  info_raw = soup.find_all('ul', class_='aux-info')\n",
        "  for i in info_raw:\n",
        "    a = i.text\n",
        "    info.append(a)\n",
        "\n",
        "\n",
        "\n",
        "# Remove both Naira and Dollar signs\n",
        "prices = [item for item in prices if item not in ['₦', '$']]\n",
        "\n",
        "\n",
        "print(len(names))\n",
        "print(len(prices))\n",
        "\n",
        "print(len(addresses))\n",
        "print(len(info))\n",
        "\n",
        "df = pd.DataFrame({'Name':names,'Price':prices,'Address':addresses,'Info':info})\n",
        "\n",
        "\n",
        "df.to_csv('Lagos_properties.csv')"
      ]
    }
  ]
}